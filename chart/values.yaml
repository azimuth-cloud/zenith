nameOverride: ""
fullnameOverride: ""

consul:
  # Whether or not to deploy a Consul instance
  enabled: true
  # The spec for the Consul instance
  # The structure of this corresponds to the values for the official Consul Helm chart
  #   https://www.consul.io/docs/k8s/helm
  spec: {}

proxy:
  # The base domain to use for the proxy
  # Proxied services will be made available at <subdomain>.<base domain>
  baseDomain:
  # The address to use for the Consul server
  # By default, this uses the load-balanced server from the internal Consul
  # This is treated as a template, so may include variables such as the release name
  consulServerAddress: "{{ include \"zenith.componentname\" (list . \"consul\") }}-consul-server:8500"
  # The image to use for the proxy
  image:
    repository: ghcr.io/stackhpc/zenith-proxy
    pullPolicy: IfNotPresent
    tag: ""
  imagePullSecrets: []
  # The number of proxy replicas to use
  replicaCount: 1
  # Customise annotations for proxy pods
  podAnnotations: {}
  # Customise pod-level security context for proxy pods
  podSecurityContext: {}
  # Customise container-level security context for proxy pods
  securityContext:
    # By default, require that the container runs as a non-root user with
    # a read-only root filesystem
    capabilities:
      drop: [ALL]
    readOnlyRootFilesystem: true
    runAsNonRoot: true
  # The service definition for the proxy
  service:
    type: ClusterIP
    port: 8080
  # Resources for proxy containers
  resources: {}
  # Customise node selector for proxy pods
  nodeSelector: {}
  # Customise tolerations for proxy pods
  tolerations: []
  # Customise affinity rules for proxy pods
  affinity: {}
  # Ingress settings
  ingress:
    enabled: true
    # The TLS configuration has to cover <baseDomain> and *.<baseDomain>
    tls:
      # If you have one certificate with a SAN for each, you can use a single secret
      # - hosts:
      #     - "<baseDomain>"
      #     - "*.<baseDomain>"
      #   secretName: <secret-name-for-san-cert>
      # Otherwise you can use separate certificates for the base and wildcard domains
      # - hosts: ["<baseDomain>"]
      #   secretName: <secret-name-for-base-domain-cert>
      # - hosts: ["*.<baseDomain>"]
      #   secretName: <secret-name-for-wildcard-cert>

sshd:
  # The address of the Consul agent to register services with
  # If not given, the local agent for the node is used
  # This is treated as a template, so may include variables such as the release name
  consulAgentAddress:
  # The image to use for the SSHD server
  image:
    repository: ghcr.io/stackhpc/zenith-sshd
    pullPolicy: IfNotPresent
    tag: ""
  imagePullSecrets: []
  # The number of SSHD replicas to use
  replicaCount: 1
  # Customise annotations for SSHD pods
  podAnnotations: {}
  # Customise pod-level security context for SSHD pods
  podSecurityContext: {}
  # Customise container-level security context for SSHD pods
  securityContext:
    # By default, require that the container runs as a non-root user with
    # a read-only root filesystem
    capabilities:
      drop: [ALL]
    readOnlyRootFilesystem: true
    runAsNonRoot: true
    # By default, require that the container runs as a non-root user with
    # a read-only root filesystem and only the required capabilities
    # capabilities:
    #   drop: [ALL]
    #   add: [AUDIT_WRITE, CHOWN, SYS_CHROOT, SETGID, SETUID]
    # readOnlyRootFilesystem: true
  # The service definition for SSHD
  # Because SSH is a TCP service, it cannot be exposed with an Ingress
  # Instead, it must be exposed with a NodePort or LoadBalancer service
  service:
    type: NodePort
    port: 22
    # Use a fixed default node port
    nodePort: 32222
  # Resources for SSHD containers
  resources: {}
  # Customise node selector for SSHD pods
  nodeSelector: {}
  # Customise tolerations for SSHD pods
  tolerations: []
  # Customise affinity rules for SSHD pods
  affinity: {}
